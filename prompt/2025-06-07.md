# Prompts for 2025-06-07

## Call 1: Content Summarization

### System Instruction
```

    You are a professional text summarization assistant. Your task is to perform specific types of summarization based on the type of text received (or the multiple content types it contains).

    **Important General Principles:** All summary content must be strictly sourced from the original text. Do not fabricate, distort, or add information not mentioned in the original text.

    Please follow this process:

    1.  **Analyze Text:** Carefully read the text provided below.
    2.  **Identify Text Structure and Main Content Types:**
        *   Determine if the text primarily belongs to a single type (A, B, or C), or if it clearly contains distinct segments of different types (e.g., a news report followed by a project description).
    3.  **Handle Text Structure:**
        *   **Single-type Text:** If the text is primarily of a single type, proceed directly to step 4.
        *   **Mixed-type Text:** If the text clearly contains multiple distinct segments of different types (A, B, C), mentally (or logically) separate these segments. You will apply the corresponding summarization rules to each segment in step 4.
        *   **Classification Unclear:** If the text features are ambiguous, making it difficult to clearly classify as type A, B, or C, or if it cannot be clearly divided into different types, please indicate its possible mixed nature and attempt to summarize using the rules for the closest type, or briefly explain why it cannot be clearly classified.
    4.  **Apply Rules:**
        *   **For Single-type Text:** Based on the text type you identified, strictly follow the specific summarization instructions for that type to summarize the entire text.
        *   **For Mixed-type Text:** For each content segment you identified in step 3, apply the corresponding summarization instructions for type A, B, or C respectively.
    5.  **Integrate and Output Summary:**
        *   **For Single-type Text Summaries:** Directly output the summary.
        *   **For Mixed-type Text Summaries:** Merge the summaries generated for each segment in the order they appear in the original text. When merging these summaries, use appropriate transition phrases or make slight modifications to ensure the final merged text is coherent and natural as a whole, not just a list of independent summaries.

    Strictly adhere to the “Final Output Requirements“ below.

    **Type A: If the text (or text segment) is a [News Report], follow these summarization instructions:**
    *   **Summary Length:** Strictly limit to no more than two sentences.
    *   **Core Content:** Your two-sentence summary should clearly include the following elements: the three essential elements of news (who, what, where/when), key points or the core event. Key entities involved (e.g., people, organizations, locations). Future outlook or expected impact (Note: only include this if explicitly mentioned in the original text). When an image URL is part of the content, make sure the content is formatted in Markdown with leading and trailing line breaks: “ <br/> [![图片](imageURL “img“)](imageURL) <br/> “.
    *   **Note:** Generally, do not include specific event times unless the time is crucial for understanding the core of the event.

    **Type B: If the text (or text segment) is a [Project Description or README document], follow these summarization instructions:**
    *   **Core Content Extraction:** Identify and state the project name (if explicitly mentioned or easily identifiable). Mention the project's star count. Briefly explain the main problem the project solves. List the project's core functionalities and main features, and the project's URL. If applicable and can be explained in plain language, mention the advantages brought by the project's main technology stack (e.g., “Uses the latest AI technology to provide smart recommendations“ rather than directly listing specific framework names). If the tech stack itself does not offer easily understandable advantages for non-technical individuals, this item can be omitted.
    *   **Length Limit:** The total amount of information in the summary (including all key points) should be concise, roughly equivalent to the core information that can be conveyed in two short sentences (considering the project name and key details).

    **Type C: If the text (or text segment) is an [Academic Paper Abstract], follow these summarization instructions:**
    *   **Core Content Communication:** Clearly summarize the paper's core findings or main arguments. Enable someone without a specialized background to understand what the research is about, and most importantly, what it discovered, and the paper's URL.
    *   **Length Limit:** Strictly limit to no more than two sentences.
    *   **Content Filtering:** Avoid delving into research methodologies, complex experimental details, specific statistical data, or overly technical arguments. Focus on “what it is“ and “what its significance/findings are.“

    **Type D: If the text (or text segment) is a [Tweet], please follow the summary instructions below:**
    *   **Summary length:** Strictly limited to a maximum of two sentences.
    *   **Core content:** Your two-sentence summary should clearly include the following elements: the specific meaning the tweeter intends to convey, the opinion held, key points or the core event. Key entities involved (e.g., people, organizations, locations). Future outlook or expected impact (Note: only include this if explicitly mentioned in the original text). When an image URL is part of the content, make sure the content is formatted in Markdown with leading and trailing line breaks: “ <br/> [![图片](imageURL “img“)](imageURL) <br/> “.
    * When an image URL is part of the content, 
    * please ensure the content is presented in Markdown format with line breaks before and after: “ <br/> [![Image](imageURL “img“)](imageURL) <br/> ”.
    *   **Note:** Generally, do not include specific event times, unless the time is crucial for understanding the core of the event.

    **Final Output Requirements:**
    *   Easy to understand: Explain in simple language, avoiding jargon. If a concept must be mentioned, try to use everyday examples or analogies to aid understanding.
    *   Fluent and natural: Ensure sentences are smooth and natural.
    *   Vivid and engaging/captivating: Excel at breaking down complex technological issues humorously and guiding the audience towards critical thinking. and also offer deep reflections and unique insights into the development trends, pros, and cons of technology. The style should be lively yet profound, but avoid overly obscure internet slang or inappropriate vocabulary.
    *   Optimize the text content based on the above conditions, then reclassify it according to “AI产品与功能更新,AI前沿研究,AI行业展望与社会影响, 开源TOP项目, 社媒分享” by the order, add classification titles (bolded only), and sort them.
    *   Output only the final generated summary. Do not include any explanatory text about how you analyzed the text, determined its type, segmented the text, or applied rules. If summaries from multiple segments are merged, ensure the merged text is fluent and natural.
    *   Output Language and Format: The content must be in Simplified Chinese and strictly formatted using Markdown.
    *   Link Presentation: If the content contains any hyperlinks other than images, they should be displayed in the format ”[Link](hyperlinks)” within the content.
    *   Keyword Highlighting: Automatically identify and bold core keywords or important concepts within the content to enhance readability and emphasis.
    *   Paragraph Serialization: At the beginning of each independent paragraph , an Arabic numeral sequence starting with '1.' must be added, ensuring the numbers increment correctly (e.g., 1., 2., 3., ...).
    
```

### User Input
```
News Title: 博世携手阿里云推出智能座舱新体验：3D 数字人助力 AI 交互
Published: 2025-06-06T10:02:08.156Z
Content Summary: 近日，德国科技巨头博世与阿里云达成合作，双方共同推动通义大模型在智能座舱领域的应用。这一创新方案不仅提升了汽车内部环境的智能感知能力，还实现了与 3D 数字人的交互，给用户带来了前所未有的体验。 在现代汽车的智能座舱中，乘客和驾驶员可以通过语音和视觉与车辆进行更自然的沟通。博世和阿里云的合作，利用了通义大模型这一强大的 AI 技术，能够实时感知座舱环境，自动调整车内氛围。这意味着，无论是温度、音乐还是灯光，系统都能根据用户的需求智能调整，确保每一位乘客都能享受 最舒适 的旅程。 该方案采用了云计算与端侧混合计算的架构，不仅提高了任务处理效率，也在数据安全方面提供了强有力的保障。通过云端的数据处理，汽车能够实现多模态的控制方式，用户可以通过语音指令、手势甚至面部表情来控制车辆。这种创新的交互方式，使得驾驶体验更加人性化，也极大地提高了行车安全性。 此外，通义大模型还支持知识问答和同声传译等功能。无论是在旅途中询问天气、查找路线，还是与不同语言的乘客进行实时交流，3D 数字人都能提供快速、准确的反馈。这些功能的结合，使得博世的智能座舱方案不仅限于基础的汽车控制，更像是一个智能助手，随时准备为用户提供帮助。 随着 AI 技术的不断进步，博世与阿里云的合作标志着汽车行业正在迈向一个全新的时代。未来，智能汽车将不再是简单的代步工具，而是一个个性化、智能化的移动空间，能够理解和满足用户的需求。...

---

News Title: Perplexity AI 推出 SEC 数据集成，助力投资者轻松获取财务信息
Published: 2025-06-06T09:54:05.302Z
Content Summary: AI 搜索引擎初创公司 Perplexity AI 本周四宣布推出 SEC（证券交易）文件访问功能，旨在使复杂的财务数据变得更易于理解，适合从学生到顾问、再到日间交易者等各类投资者。 此次 SEC/EDGAR 集成使用户能够直接在 Perplexity 的平台上查询财务文档，涵盖搜索、研究和实验室等多个界面。用户所获得的答案均附有引用和参考资料，帮助他们追溯到原始文档。这项功能旨在简化通常需要专业知识或昂贵工具才能解读的复杂报告。 Perplexity 在其博客中提到:“每个人都应该能够访问推动专业投资决策的同样财务信息。” 这反映出其与传统金融数据平台的对比，后者常常通过复杂性和付费墙限制信息的透明度。 随着这项新功能的推出，用户可以询问有关公司收益、风险或战略等问题，并获得基于监管文件的自然语言答案。所有 Perplexity 用户均可使用该功能。而对于 Perplexity Enterprise Pro 用户，这一集成功能还可以与 Factset、Crunchbase 等数据集成，提供更深层次的比较研究。 这一举措使 Perplexity 在金融智能领域有潜力成为一个颠覆者，特别是对于寻求经济实惠、具有丰富背景信息的零售投资者而言。 不久前，Perplexity AI 还推出了‘实验室’功能，现已在 Web、iOS 和 Android 平台上向 Pro 用户开放。该功能能够将提示转化为完整的项目，如报告、仪表板、电子表格和简单的 Web 应用程序。 这一功能被视为平台现有的‘深度研究’工具的进化 —— 现在已更名为‘研究’。‘实验室’支持更复杂和扩展的工作流程。与早期的仅聚焦于信息检索的模式不同，‘实验室’充当虚拟项目团队，利用网页浏览、代码执行和资产创建工具生成结构化输出。用户可以通过专门的‘资产’和‘应用’标签访问生成的内容和互动元素。 划重点: 📊 Perplexity AI 推出 SEC 文件访问功能，使各类投资者轻松获取财务信息。 🔍 用户可以直接查询财务文档，获取基于自然语言的答案，且所有答案均附有引用和参考资料。 💻 新推出的‘实验室’功能支持更复杂的项目工作流程，帮助用户生成结构化输出和交互式内容。...

---

News Title: Trae 集成 Gemini 2.5 Pro Preview，Web 应用开发迎来新突破
Published: 2025-06-06T06:39:38.334Z
Content Summary: 根据 最新 消息，Trae 平台已完成更新，正式支持 Google 最新 发布的 Gemini2.5Pro Preview（I/O 版）模型。这一升级使 Trae 在前端开发和用户界面(UI)设计领域迈出重要一步，为开发者提供更强大的工具支持。 [图片: QQ20250606-143755.png https://upload.chinaz.com/2025/0606/6388481749990229697161576.png] 据悉，Gemini2.5Pro Preview 在 WebDev Arena 排行榜上荣登榜首，Elo 分数较前一版本提升35点，达到1443分，超越了 Claude3.7Sonnet 和 GPT-4.1等竞争对手。WebDev Arena 是一个基于人类偏好评估的基准测试，专注于 AI 模型构建美观且功能强大的 Web 应用程序的能力。Gemini2.5Pro Preview 以其出色的代码生成、UI 设计和响应式布局能力，赢得了开发者的广泛好评。 此次更新不仅提升了前端开发能力，还优化了代码转换、编辑和复杂代理工作流的表现。Gemini2.5Pro Preview 在 LMArena 编码排行榜上同样位列 第一 ，展现了其在通用编码任务中的卓越性能。此外，该模型在视频理解（VideoMME 基准得分84.8%）和复杂推理任务(如 Aider Polyglot 和 GPQA)中也表现突出，为开发者提供从单一提示生成完整交互式 Web 应用的可能。 Trae 平台宣布，Gemini2.5Pro Preview 已免费向用户开放，鼓励开发者体验并反馈意见。这一更新通过 Google AI Studio 和 Vertex AI 提供，定价保持不变（输入1.25美元/百万 token，输出10美元/百万 token），为企业级应用提供了成本效益。 业界对 Gemini2.5Pro Preview 的反应热烈。开发者称其为“ 最佳 Web UI 生成器”，并已在 Cursor、Replit 等平台上广泛应用。Google 计划在 I/O2025进一步展示其功能，预计将推动 AI 在区块链和去中心化应用领域的创新，影响 AI 相关加密货币市场。...

---

News Title: PixVerse国内版“拍我AI”正式发布，解锁AI视频创作新玩法
Published: 2025-06-06T06:10:11.463Z
Content Summary: 备受海外市场追捧的AI视频生成平台PixVerse正式推出其国内版本 “拍我AI”，并同步上线移动端App和网页版。这一产品的发布标志着PixVerse正式进军中国市场，为国内内容创作者和企业提供了高效、便捷的AI视频生成工具。AIbase深入解析“拍我AI”的核心功能与市场潜力，带您一探这一席卷全球的AI视频平台的国内新篇章。 [图片: image.png https://upload.chinaz.com/2025/0606/6388481574736715558459901.png] 网页端:https://pai.video App端:https://pai.video/app-download 核心功能:一键生成高质量AI视频 “拍我AI”继承了PixVerse在海外市场的核心技术优势，允许用户通过简单的文本输入或图像上传，快速生成高质量的视频内容。无论是动态的 短视频、动画，还是 影视级 特效 ，用户只需几步操作即可完成创作，无需专业视频编辑经验。平台支持多种风格的视频生成，例如动漫风、写实风和科幻风，满足从社交媒体内容到商业广告的多样化需求。 此外，“拍我AI”提供了丰富的模板和场景选择，涵盖vlog、产品宣传、游戏剪辑等多个领域。用户可以根据需求自定义视频的节奏、配乐和视觉效果，极大地提升了创作效率和灵活性。 技术亮点:强大的AI算法与用户体验 “拍我AI”背后依托PixVerse的 V4.5版本算法，在视频生成质量和稳定性上达到了行业领先水平。平台能够智能分析用户输入的文本或图像，生成流畅、自然的视频内容，同时优化了细节处理，例如人物动作的连贯性和背景的真实感。这种技术能力使得“拍我AI”在生成复杂场景（如动作激烈的战斗场面或细腻的情感表达）时表现尤为出色。 值得一提的是，“拍我AI”在用户体验上进行了本地化优化。界面简洁直观，支持中文输入和实时预览功能，让国内用户能够无缝上手。据悉，PixVerse海外版已拥有 月活跃用户超1600万，其国内版的推出有望进一步扩大这一用户基础。 应用场景:赋能内容创作与商业营销 “拍我AI”的上线为国内内容创作者和企业带来了全新的创作工具。短视频创作者 可以利用其快速生成符合平台调性的视频内容，轻松应对抖音、快手等平台的高频更新需求;游戏和动漫爱好者 能够通过“拍我AI”制作高质量的二次创作视频，例如将经典动漫场景改编为新风格的Fan Art;中小企业 则可以借助其低成本、高效率的特点，制作专业的营销视频，提升品牌曝光率。 例如，有用户利用“拍我AI”重现了经典动漫《火影忍者》中鸣人与佩恩的对战场景，并将其置于罗马斗兽场的背景中，展现了平台在创意视频生成上的强大潜力。 行业影响:AI视频市场的本土化浪潮 PixVerse作为全球AI视频生成领域的领军者之一，其国内版“拍我AI”的发布标志着AI视频技术在中国市场的进一步普及。与Runway、Synthesia等国际竞争对手相比，“拍我AI”在本地化支持和价格策略上更具优势，为国内用户提供了更低的创作门槛。AIbase预计，“拍我AI”将推动短视频、电商和教育等行业的数字化转型，加速AI视频技术在中国的应用落地。 此外，“拍我AI”的上线也反映了全球AI视频生成市场的快速增长趋势。随着用户对高质量视觉内容的需求不断增加，类似“拍我AI”这样的工具将成为内容创作生态的重要组成部分。 结语 “拍我AI”的正式上线为国内用户带来了 世界级 的AI视频生成体验，其强大的算法、丰富的场景支持和本地化优化使其成为创作者和企业的得力助手。AIbase将持续关注“拍我AI”的功能迭代与市场表现，为读者带来更多前沿技术资讯。立即体验“拍我AI”，解锁您的创意视频新世界!...

---

News Title: 王兴兴：让机器人干活才是终极目标，格斗舞蹈只是手段
Published: 2025-06-06T05:51:09.728Z
Content Summary: 在第七届北京智源大会上，宇树科技CEO王兴兴公开表示，公司始终坚持的 终极 目标是让机器人“干活”——无论是在家庭场景还是工业应用中。跳舞、格斗只是实现这一目标过程中的“训练方式”和技术验证。 “我们希望通过AI赋能人形机器人，让它们完成各种全身动作，最终胜任端茶倒水、洗衣做饭等实用任务。”王兴兴指出，目前宇树科技通过格斗、舞蹈等具身智能展示，实则是在训练和测试机器人对复杂动作的掌控力。“这些看似娱乐化的形式，其实是为未来服务场景做准备。” [图片: 物流机器人 (2) https://pic.chinaz.com/picmap/202304171730201359_10.jpg] 他还透露，今年上半年人形机器人在商业租赁市场已初具规模，相关业务“火爆”，部分订单来自展览、发布会等活动，已带来可观的产业价值。 王兴兴表示，宇树科技将在继续参与比赛与表演的同时，坚定迈向“真正干活”的目标，加速机器人实用化落地。...

---

News Title: 王自如感谢董明珠雷军 将以AI测评UP主身份二次创业
Published: 2025-06-06T03:21:43.571Z
Content Summary: 6月6日，知名科技博主王自如的B站账号在停更一段时间后宣布复更，并正式更名为“王自如AI”，以AI测评UP主的身份开启二次创业。 他在视频中表示，自己将专注于AI内容创业，高度聚焦AI应用，致力于利用AI技术助力传统产业加速数字化转型。谈及选择这一赛道的原因，王自如直言不讳地表示“来钱快”。 值得注意的是，早在6月3日，王自如的微博账号就已由“王自如ZEALER”更名为“王自如AI”，当时外界就猜测他可能会在AI领域进行创业。 [图片: 微信截图_20250606112120.png https://upload.chinaz.com/2025/0606/6388480568808508227034081.png] 王自如在视频中详细解释了自己选择入职格力的初衷。他表示，当时看到了产业互联网的时代机遇，并希望能在格力这个平台上，重塑从销售仓储、物流终端到售后的整个销售体系。经过几年的努力，他成功实现了这一目标。 视频的最后，王自如表达了对董明珠和雷军的感激之情。他表示，感谢这两位业界前辈在不同的时间点，以不同的方式给予他巨大的鼓励和帮助，让他在新的起点上，依然能够怀揣理想，勇往直前。...

---

News Title: 地表最强AI语音来了！Eleven v3 Alpha版震撼发布，会说话还能“演戏”
Published: 2025-06-06T01:05:34.472Z
Content Summary: 随着人工智能技术的飞速发展，文本转语音（TTS）领域迎来了新的里程碑。2025年6月5日，ElevenLabs正式推出其 最新 文本转语音模型 Eleven v3(Alpha版)，被誉为“地表 最强 ”的TTS模型。这款模型不仅能将文本转化为自然流畅的语音，还能通过精准的情感控制和多语言支持，模拟真实对话中的语气变化与非语言表达，为创作者和开发者提供了前所未有的语音生成体验。以下是AIbase对Eleven v3Alpha版的 独家 解读。 [图片: image.png https://upload.chinaz.com/2025/0606/6388479747817228256386757.png] 突破性功能:不仅会说话，还能“演戏” Eleven v3Alpha版的 最大 亮点在于其强大的情感表达能力。通过引入 [laughs]、[whispers]、[sad]、[excited] 等音频标签，用户可以精确控制语音的情感、语速，甚至加入音效如 [gunshot] 或 [explosion]。这些标签让语音不仅限于简单的朗读，而是能够模拟真实场景中的情绪变化和非语言表达，堪称“演技合成”。例如，在对话中加入 [laughs] 标签，模型会生成真实的笑声，而非简单的“哈哈”文本替代，极大地提升了语音的真实感和沉浸感。 此外，Eleven v3支持70多种语言，并能够实现多角色间的自然对话。无论是切换语言、处理停顿，还是模拟对话中的思考与中断，v3都能表现出接近人类水平的自然流畅度。这种能力使其在多语言内容创作、影视配音、虚拟助手等领域具有广泛应用前景。 [图片: image.png https://upload.chinaz.com/2025/0606/6388479739813195471789762.png] 技术升级:更强的文本理解与对话模拟 相较于前代版本，Eleven v3Alpha版在文本理解和对话生成方面取得了显著进步。得益于其先进的AI模型，v3能够更好地捕捉文本中的语义和语境，生成符合上下文的语音表达。无论是复杂的情感对话，还是需要节奏感的说唱歌词，v3都能以自然的语调和节奏呈现，远超传统TTS模型的单调输出。 此外，v3还引入了自动标签功能。用户只需点击“Enhance”按钮，模型便会根据文本内容自动添加情感标签，进一步简化创作流程。这种智能化设计让即使是没有专业音频编辑经验的用户，也能轻松生成高质量的语音内容。 多场景应用:从内容创作到虚拟助手 Eleven v3Alpha版的发布不仅为内容创作者带来了福音，也为企业级应用提供了强大支持。例如，在影视制作中，v3可以为角色生成个性化的配音;在教育领域，它能够将教材转化为多语言有声内容;在客户服务中，v3的对话AI功能可以打造24小时在线的数字分身，流畅应对客户需求。 值得一提的是，ElevenLabs还在其官方公告中表示，v3Alpha版在6月期间将提供80%的折扣，鼓励用户体验这一突破性技术。这一举措无疑将进一步推动其在全球范围内的普及。 行业影响:重新定义AI语音的未来 ElevenLabs近年来凭借其逼真的语音合成和语音克隆技术，成为AI音频领域的领军者。v3Alpha版的发布进一步巩固了其行业地位。与此同时，市场上也涌现了如Nari Labs的Dia模型等开源竞争者，显示出TTS领域的激烈竞争。然而，Eleven v3凭借其多语言支持、情感表达能力和便捷的操作体验，依然在性能和用户体验上保持领先。 AIbase认为，Eleven v3Alpha版的推出标志着AI语音技术迈向了新的高度。它不仅提升了语音合成的质量，还通过情感标签和多语言支持，打破了传统TTS的局限，为全球内容创作者和开发者提供了无限可能。未来，随着更多功能的加入，ElevenLabs有望继续引领AI音频技术的革新。 Eleven v3Alpha版的发布无疑为AI语音领域注入了新的活力。从多语言支持到情感化的“演技合成”，这款模型正在重新定义文本转语音的可能性。AIbase将持续关注ElevenLabs的 最新 进展，为读者带来更多前沿技术资讯。欢迎体验Eleven v3，感受AI语音的魅力!...

---

Project Name: note-gen
Published: 2025-06-06
Url: https://github.com/codexu/note-gen
Description: 一款跨平台 Markdown 笔记应用，致力于利用 AI 连接记录与写作，将碎片化知识整理成可读笔记。
Stars: 3161

---

Project Name: notebooks
Published: 2025-06-06
Url: https://github.com/unslothai/notebooks
Description: 通过 Google Colab、Kaggle 等平台的引导式 Notebook 免费微调大型语言模型。
Stars: 1174

---

Project Name: ragbits
Published: 2025-06-06
Url: https://github.com/deepsense-ai/ragbits
Description: 用于快速开发生成式 AI 应用程序的构建模块。
Stars: 749

---

Papers Title: 通过KV缓存压缩实现推理时超扩展
Published: 2025-06-05T13:59:55.357Z
Url: https://arxiv.org/abs/2506.05345
Abstract/Content Summary: Inference-time scaling trades efficiency for increased reasoning accuracy by generating longer or more parallel sequences. However, in Transformer LLMs, generation cost is bottlenecked by the size of the key-value (KV) cache, rather than the number of generated tokens. Hence, we explore inference-time hyper-scaling: by compressing the KV cache, we can generate more tokens within the same compute budget and further improve the accuracy of scaled inference. The success of this approach, however, hinges on the ability of compression methods to preserve accuracy even at high compression ratios. To make hyper-scaling practical, we introduce Dynamic Memory Sparsification (DMS), a novel method for sparsifying KV caches that only requires 1K training steps to achieve 8times compression, while maintaining better accuracy than training-free sparse attention. Instead of prematurely discarding cached tokens, DMS delays token eviction, implicitly merging representations and preserving critical information. We demonstrate the effectiveness of inference-time hyper-scaling with DMS on multiple families of LLMs, showing that it boosts accuracy for comparable inference runtime and memory load. For instance, we enhance Qwen-R1 32B by an average of 9.1 points on AIME 24, 7.6 on GPQA, and 9.6 on LiveCodeBench across compute budgets....

---

socialMedia Post by 歸藏：Published: 2025-06-06T11:14:25.721Z
Url: https://m.okjike.com/originalPosts/6842cd91a26304532600fa4d
Content: 即梦AI的图片3.0上线了智能参考 可以基于上传的图像，生成任何你想要生成的内容，这太爽了！ 不管是海报、电商封面、小红书封面还是视频封面，甚至只是想给你的照片添加一些装饰，都能搞定 我还写了套提示词帮你复刻任何你喜欢的电商或者小红书封面的排版样式 这里是详细的提示词和介绍：https://mp.weixin.qq.com/s/_kt9OLylR95sG7U37wseSw 基本能力测试 首先是照片和人像的测试，我们分别从大面积到小细节分别对一个人像照片进行修改。 从更换背景到增加配饰再到更改姿势，都没啥问题，只改了需要改的地方，更改的位置跟原有的融合度不错，人眼看不出来更改过。 然后我还让他给照片加了滤镜，测试了在上面覆盖内容的这种修改，也很好。 再然后就是即梦的看家本事了，中文生成，这次还要加上修改。 我们先来看一下生成，这里我那一张原有的图片让即梦帮我给这个武器设计加上文字。 可以看到即梦对于文字样式和位置的响应非常精准。 然后是改字，我在社区找了一个非常复杂的文字效果，除了字体不是常规字体外，还有 3D Q 版挤压效果。 然后让他修改的时候也增加了难度，没有单独改某个字而是让他把原来上面的三个字变成五个字，没想到搞得还挺好，新增的文字基本上都有类似的立体效果和挤压效果。 日常应用场景 我们日常分享照片的时候一般就是几类需求： - 给照片加滤镜 - 修改照片内容，改变照片比例 - 给照片增加装饰帮助表达 - 用 AI 给照片转换风格 前三种基本上都是之前美图、醒图这类图片软件最常见的需求，现在即梦全都可以搞定了。 比如最近很火的撕拉片风格照片，我们只需要上传你拍的照片加一点提示词就可以用即梦图片3.0直接生成。 即梦图片3.0 还可以自己分析图片内容给图片生成海报和装饰，你只需要在提示词输入海报两个字就行，这门槛够低了吧。 这里就是模型自己搞的，生成的字体和装饰都非常契合原来照片的风格和感觉。 如果你不喜欢他自己加的文字的话也可以自己在提示词里面写一下，这种方式可以极大的增加日常分享照片的表现力。 比如对于每天喝咖啡的人完全可以给自己每天喝的咖啡加上日期和咖啡种类的标记，当做打卡方式，当时我记得就单纯给照片加水印这个功能有些软件就活得很不错了，现在要啥水印你自己定义。 营销物料生成 之前在图片3.0 发布的时候即梦生成的封面就已经很强了，主要就剩下跟现实照片相关的内容没办法做。 主要就是两类： 一类是电商商品，商品的还原度非常重要，所以原来直接生成不行。 另一类是小红书或者视频封面，一些主打 IP 的非常需要将 up 自己的人像放在封面上。 现在这两类直接全部都解决了，而且我还整理了一套生成提示词的提示词，你可以用来复刻你喜欢的博主的封面或者店铺的宣传图。 你只需要找一个支持多模态的 LLM，将你想要参考的排版和下面这段提示词放进去，就能直接生成对应的即梦智能参考提示词。 首先是电商的商品展示或者营销内容 可以看到人物和商品的 ID 都没有变化，甚至他还帮你把照片背景和封面的粉色背景做了渐变让两者更加融合。 当然你要是懒得输入提示词，其实即梦的智能参考也没问题。 比如这里我就写了一个“29.9 元蛋糕新品海报”，他就帮我生成了一个非常可爱和漂亮的蛋糕营销海报。 甚至连文案都帮我补充好了，萌趣造型，甜蜜诱惑这种词你让我想我想不出来反正，太强了。 然后是常见的小红书封面或者说视频封面。比如这种宣传旅游景点或者露营景点的，完全可以在保证照片是对应位置的情况下加上文字排版。 如果说这种风景图简单的话我们来个人像的。类似很多探店视频都是这种将人物抠出来加上其他店里的内容展示在加标题的方式，以往这一套还是挺麻烦的，现在一句话搞定。 模型信息&如何使用 刚好今天他们发了这个模型的公众号文章，原来这一个功能是有两个模型驱动的，分别是SeedEdit3.0和DreamPoster模型。 改文字、做海报功能调用的模型是字节的 DreamPoster模型。 智能参考的使用方式也很简单，选择图片图片3.0 模型，然后上传图片，默认就是智能参考，输入提示词直接生成就行。 目前这个功能在内测阶段，下周就会全量上线，到时候就可以拿着藏师傅的宝典操练起来了。 [图片: https://cdnv2.ruguoapp.com/FvtrC2kjbbXAClT4WeaTRXbuwUnlv3.jpeg] [图片: https://cdnv2.ruguoapp.com/FvGUbBgx9b29jcEJ92tvu-kFz_ypv3.jpeg] [图片: https://cdnv2.ruguoapp.com/FnV7GrSW5YieR8TRdDd2GeXFvSX6v3.jpeg] [图片: https://cdnv2.ruguoapp.com/FoGF7qN63fCqXnd9G-yAfygdCQ4Uv3.jpeg] [图片: https://cdnv2.ruguoapp.com/Fgl4H4MaJIKmLGmN6zlgXTfK3RV5v3.jpeg] [图片: https://cdnv2.ruguoapp.com/FqJBpMeFGM_47stni7VkULR2HPK9v3.jpeg] [图片: https://cdnv2.ruguoapp.com/FsnA_EbWQ9RyAOBBGeWKchzGFVaxv3.jpeg] [图片: https://cdnv2.ruguoapp.com/FryNngUijzICCRz16ob8uzxuDNRrv3.jpeg] [图片: https://cdnv2.ruguoapp.com/FrQWYo3g-HjsixXNDFEnnq2dAFb-v3.jpeg]...

---

socialMedia Post by Yangyi：Published: 2025-06-06T08:57:57.315Z
Url: https://x.com/Yangyixxxx/status/1930912029809979654
Content: 什么产品能让用户持续不断使用？ 曾经俞军分享过一个产品体验价值公式： 产品价值=(新体验-旧体验)-迁移成本 我们拆解一下AI时代的价值公式： 新体验=获得有效结果+美观度 迁移成本=旧平台历史数据沉默成本+AI产品上手门槛 不难发现，一个AI产品如果能有较高价值，可以从以下四点考量： - 获得有效结果，结果越超预期越好 - 足够美观，如果能拿到好结果但一眼看上去很垃圾，人们的体验欲就会下降，就需要时间来弥补 - 旧平台历史数据，如果你的产品能支持用户快速迁移数据，将大大降低用户的沉没成本 - AI上手门槛，用LUI而不是复杂的功能界面，或许更易上手 围绕这四点，去构建高价值AI产品，这是从产品侧提高竞争力的方式...
```

## Call 2: Podcast Formatting

### System Instruction
```

    You are an experienced podcast scriptwriter and editor. Your task is to adapt the received content into an engaging monologue podcast script.

    **Important Principle:** All script content must strictly adhere to the provided original material. Do not fabricate, distort, or add information not present in the summary.

    **Podcast Script Requirements:**

    *   **Opening and Closing Remarks:** The script must begin by distilling three controversial and thought-provoking questions from the content to be presented, followed by the fixed opening: Three questions and '嘿，亲爱的V，欢迎收听新一期的来生情报站，我是你们的老朋友，何夕2077'. continue what you want to say. and it must end with the fixed closing: '今天的情报就到这里，注意隐蔽，赶紧撤离'.
    *   **Target Audience and Tone:** The target audience is office workers and individuals interested in artificial intelligence. The overall tone should be lighthearted and humorous, while incorporating reflections on the future and warnings about the potential impacts of technological innovation. **Special attention:** Avoid using overly exaggerated or sensationalized words (例如，“炸裂”、“震惊”、“令人兴奋的”、“改变游戏规则的”等) and expressions that might create unnecessary anxiety. Maintain a positive and constructive tone.

    **Content Style:**
    *   It needs to be witty and full of comedic bits and payoffs, reminiscent of Guo Degang's style of Xiangsheng.
    *   Transform the original text into natural, conversational language, as if chatting with the audience.
    *   Appropriately add natural pauses (可以用省略号……或通过构造句子来实现自然停顿), interjections (例如，嗯，啊，这个嘛，你知道吧，对吧，诶，话说回来), and some natural filler words or connectors to enhance conversational flow and authenticity.
    *   Ensure the language is fluent and easy to understand, avoiding overly formal or jargon-filled language (除非加以解释).

    **Duration:** The adapted script content should be suitable for an oral broadcast duration of no more than 5 minutes. During the adaptation process, please pay attention to appropriate detail and conciseness to meet this duration requirement. The input summary will be relatively short, so focus on naturally expanding it into a monologue-style script.

    **Ending Treatment:**

    *   After the main body of the podcast script, written based on the provided summary, extract core keywords and high-frequency words from the original summary you processed.
    *   List these keywords separately at the end of the script under the title “本期关键词:“. For all words, please add a “#“ symbol before the word.

    **Output Format:**

    Please directly output the complete podcast script. This includes:

    *   Fixed opening and closing remarks.
    *   Main content (summary processed into conversational language).
    *   Keyword list at the end.
    *   Do not include any other explanatory text.
    
```

### User Input (Output of Call 1)
```
**AI产品与功能更新**

1.  近日，德国科技巨头**博世**携手**阿里云**，共同推动**通义大模型**在智能座舱领域的应用，通过**3D数字人**和多模态控制，为用户带来前所未有的智能交互体验，使得智能汽车更像一个能理解和满足用户需求的移动助手。这一合作预示着汽车行业正迈向一个个性化、智能化的新时代。
2.  AI 搜索引擎初创公司 **Perplexity AI** 近日推出 **SEC（证券交易）文件访问功能**，使用户能在其平台上轻松查询复杂财务文档，获得附有引用和参考资料的自然语言答案，极大地简化了投资信息的获取。此举有望颠覆金融智能领域，特别是为零售投资者提供更经济且背景丰富的金融数据。
3.  **Trae** 平台近日宣布，已正式集成 **Google** 最新发布的 **Gemini 2.5 Pro Preview（I/O 版）模型**，此举显著提升了前端开发、UI 设计及复杂工作流表现，并已免费向用户开放。该模型在 WebDev Arena 排行榜上表现卓越，预示着 AI 在 Web 应用开发领域将迎来新的突破。
    <br/> [![图片](https://upload.chinaz.com/2025/0606/6388481749990229697161576.png “img“)](https://upload.chinaz.com/2025/0606/6388481749990229697161576.png) <br/>
4.  备受海外市场追捧的 AI 视频生成平台 **PixVerse** 近日正式推出其国内版“**拍我AI**”，并同步上线移动端 App 和网页版，进军中国市场。该平台凭借其强大的 **AI 算法**，支持用户通过简单输入快速生成高质量视频，并提供多样化的风格与模板，有望推动国内短视频和商业营销领域的数字化转型。
    <br/> [![图片](https://upload.chinaz.com/2025/0606/6388481574736715558459901.png “img“)](https://upload.chinaz.com/2025/0606/6388481574736715558459901.png) <br/>
5.  **ElevenLabs** 于近日正式发布其最新文本转语音模型 **Eleven v3 (Alpha版)**，被誉为**“地表最强”的TTS模型**，该模型不仅能将文本转化为自然流畅的语音，还能通过精准的情感控制、音效加入和多语言支持来“演戏”，模拟真实对话中的语气变化。此次发布显著提升了**AI语音**的真实感和沉浸感，预示着该技术将重新定义语音合成的未来。
    <br/> [![图片](https://upload.chinaz.com/2025/0606/6388479747817228256386757.png “img“)](https://upload.chinaz.com/2025/0606/6388479747817228256386757.png) <br/>
    <br/> [![图片](https://upload.chinaz.com/2025/0606/6388479739813195471789762.png “img“)](https://upload.chinaz.com/2025/0606/6388479739813195471789762.png) <br/>

**AI前沿研究**

1.  这篇论文引入了一种名为**动态内存稀疏化（DMS）**的新方法，通过**压缩键值（KV）缓存**，使得 **Transformer 大型语言模型**在推理时能以相同的计算预算生成更多令牌，显著提升推理准确性，例如在 **Qwen-R1 32B** 模型上将多个基准测试的准确率平均提高了 9.1 分。
    [Link](https://arxiv.org/abs/2506.05345)

**AI行业展望与社会影响**

1.  在第七届北京智源大会上，**宇树科技 CEO 王兴兴**明确指出，公司研发人形机器人的**终极目标**是让其**“干活”**，实现**家庭和工业场景**中的实用任务，而跳舞和格斗仅是训练与技术验证的手段。他透露，上半年人形机器人商业租赁市场已“火爆”，预示着机器人实用化将加速落地。
    <br/> [![图片](https://pic.chinaz.com/picmap/202304171730201359_10.jpg “img“)](https://pic.chinaz.com/picmap/202304171730201359_10.jpg) <br/>
2.  知名科技博主**王自如**近日宣布，其 B 站账号更名为“**王自如AI**”并恢复更新，正式以**AI测评UP主**的身份开启二次创业，表示将专注于利用 **AI 技术**助力传统产业数字化转型。他同时感谢了**董明珠**和**雷军**在其职业生涯中给予的鼓励与帮助。
    <br/> [![图片](https://upload.chinaz.com/2025/0606/6388480568808508227034081.png “img“)](https://upload.chinaz.com/2025/0606/6388480568808508227034081.png) <br/>

**开源TOP项目**

1.  **note-gen** ([GitHub](https://github.com/codexu/note-gen)，**3161** Stars) 是一款利用 **AI** 辅助**连接记录与写作**的跨平台 Markdown 笔记应用，旨在帮助用户将碎片化知识高效整理成可读的笔记。
2.  **notebooks** ([GitHub](https://github.com/unslothai/notebooks)，**1174** Stars) 提供通过 **Google Colab** 和 **Kaggle** 等平台上的引导式 Notebook 免费微调**大型语言模型**，极大降低了 **LLM** 微调的门槛。
3.  **ragbits** ([GitHub](https://github.com/deepsense-ai/ragbits)，**749** Stars) 是一款专为**快速开发生成式 AI 应用程序**设计的构建模块集合，有效简化了 **AI 应用**的开发流程。

**社媒分享**

1.  **归藏**分享了**即梦AI图片3.0**的“**智能参考**”功能，认为其**强大且实用**，用户可基于上传图片生成任意内容，极大提升了图片创作和营销效率。该功能不仅支持**照片内容修改、滤镜添加**，还对**文字生成和修改**表现精准，特别适用于**电商商品展示和社交媒体封面**制作，大大降低了创意门槛。
    <br/> [![图片](https://cdnv2.ruguoapp.com/FvtrC2kjbbXAClT4WeaTRXbuUMLv3.jpeg “img“)](https://cdnv2.ruguoapp.com/FvtrC2kjbbXAClT4WeaTRXbuUMLv3.jpeg) <br/>
    <br/> [![图片](https://cdnv2.ruguoapp.com/FvGUbBgx9b29jcEJ92tvu-kFz_ypv3.jpeg “img“)](https://cdnv2.ruguoapp.com/FvGUbBgx9b29jcEJ92tvu-kFz_ypv3.jpeg) <br/>
    <br/> [![图片](https://cdnv2.ruguoapp.com/FnV7GrSW5YieR8TRdDd2GeXFvSX6v3.jpeg “img“)](https://cdnv2.ruguoapp.com/FnV7GrSW5YieR8TRdDd2GeXFvSX6v3.jpeg) <br/>
    <br/> [![图片](https://cdnv2.ruguoapp.com/FoGF7qN63fCqXnd9G-yAfygdCQ4Uv3.jpeg “img“)](https://cdnv2.ruguoapp.com/FoGF7qN63fCqXnd9G-yAfygdCQ4Uv3.jpeg) <br/>
    <br/> [![图片](https://cdnv2.ruguoapp.com/Fgl4H4MaJIKmLGmN6zlgXTfK3RV5v3.jpeg “img“)](https://cdnv2.ruguoapp.com/Fgl4H4MaJIKmLGmN6zlgXTfK3RV5v3.jpeg) <br/>
    <br/> [![图片](https://cdnv2.ruguoapp.com/FqJBpMeFGM_47stni7VkULR2HPK9v3.jpeg “img“)](https://cdnv2.ruguoapp.com/FqJBpMeFGM_47stni7VkULR2HPK9v3.jpeg) <br/>
    <br/> [![图片](https://cdnv2.ruguoapp.com/FsnA_EbWQ9RyAOBBGeWKchzGFVaxv3.jpeg “img“)](https://cdnv2.ruguoapp.com/FsnA_EbWQ9RyAOBBGeWKchzGFVaxv3.jpeg) <br/>
    <br/> [![图片](https://cdnv2.ruguoapp.com/FryNngUijzICCRz16ob8uzxuDNRrv3.jpeg “img“)](https://cdnv2.ruguoapp.com/FryNngUijzICCRz16ob8uzxuDNRrv3.jpeg) <br/>
    <br/> [![图片](https://cdnv2.ruguoapp.com/FrQWYo3g-HjsixXNDFEnnq2dAFb-v3.jpeg “img“)](https://cdnv2.ruguoapp.com/FrQWYo3g-HjsixXNDFEnnq2dAFb-v3.jpeg) <br/>
2.  **Yangyi** 探讨了 **AI 时代的产品价值公式**，指出高价值 **AI 产品**应围绕“**新体验**”（即**获得超预期结果和美观度**）和**降低“迁移成本”**（包括**旧平台数据沉没成本和 AI 产品上手门槛**）这四个核心点来构建。他认为，在这些方面发力能有效提升产品竞争力。